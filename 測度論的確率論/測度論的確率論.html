<!DOCTYPE html>
<html>
<head>
<title>測度論的確率論.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>
<link rel="stylesheet" href="file:///d%3A/%E3%83%9E%E3%83%BC%E3%82%AF%E3%83%80%E3%82%A6%E3%83%B3/practice/github-markdown.css" type="text/css">
<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://yukimaru77.github.io/practice/github-markdown.css">
<style>
.markdown-body {
box-sizing: border-box;
min-width: 200px;
max-width: 980px;
margin: 0 auto;
padding: 45px;
}

@media (max-width: 767px) {
.markdown-body {
  padding: 15px;
}
}
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.css" integrity="sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.js" integrity="sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/contrib/auto-render.min.js" integrity="sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe" crossorigin="anonymous"></script>
<script>
  document.addEventListener("DOMContentLoaded", () => {
    renderMathInElement(document.body, {
      delimiters: [
        { left: "$$", right: "$$", display: true },
        { left: "$", right: "$", display: false },
      ]
    });
  });
  elements = document.getElementsByTagName("h2");
  console.log(elements)

</script>
</head>
<body>
  <article class="markdown-body">
<h1 id="%E6%B8%AC%E5%BA%A6%E8%AB%96%E7%9A%84%E7%A2%BA%E7%8E%87%E8%AB%96">測度論的確率論</h1>
<h2 id="%E5%88%9D%E9%A0%AD%E7%9A%84%E3%81%AA%E8%A9%B1%E5%8F%A4%E5%85%B8%E7%9A%84%E7%A2%BA%E7%8E%87%E8%AB%96">初頭的な話(古典的確率論)</h2>
<p>初頭的な話は高校の時にやっているので省略。忘れていたら(そのままでも構わないが)マセマの確率統計第1章などに書いてある。</p>
<h2 id="%E3%81%93%E3%81%93%E3%81%8B%E3%82%89%E3%81%AE%E8%A9%B1%E3%81%AE%E5%89%8D%E6%8F%90%E7%9F%A5%E8%AD%98">ここからの話の前提知識</h2>
<p>初歩的な集合論や位相空間論、測度論、ルベーグ積分などは既習とする。</p>
<h2 id="%E6%A8%99%E6%9C%AC%E7%82%B9%E4%BA%8B%E8%B1%A1%E7%A2%BA%E7%8E%87%E3%81%AE%E5%AE%9A%E7%BE%A9">標本点、事象、確率の定義</h2>
<p>$(Ω,F,P)$なる測度空間を考える。ここでさらに$P(Ω)=1$の時、$(Ω,F,P)$を <strong>確率空間</strong> と呼び、Pを <strong>確率(測度)</strong> 、$F$の元を <strong>事象</strong> 、$Ω$の元を <strong>標本点</strong> と呼ぶ。また、$P(A)$を <strong>事象Aの確率と呼ぶ。</strong></p>
<p>また、写像$P:F→R$を <strong>確率法則</strong> とも呼ばれる。</p>
<h2 id="%E7%A2%BA%E7%8E%87%E5%A4%89%E6%95%B0">確率変数</h2>
<p>$(Ω,F,P)$なる確率空間と$(R^n,B(R^n))$なる測度空間を考える。さらに写像$X:Ω→R$を考えこれがF-可測関数ならば、$X$を <strong>(d次元)確率変数</strong> という。n=1の場合特に <strong>実確率変数</strong> というが断りがない限り(測度と積分,著M-ツァピンスキにならって)確率変数とは実確率変数を指すこととする。F-可測関数とは数式にすると(n=1の場合、)</p>
<ol>
<li>fが可測関数である。つまり、任意の$B\in B(R)$の逆像$f^{-1}(B)$が$f^{-1}(B)\in F$</li>
<li>任意の区間$I$の逆像$f^{-1}(I)$が$f^{-1}(I)\in F$</li>
<li>任意の$a\in R$に対し、$\lbrace x\in X| f(x)&gt;a\rbrace \in F$。つまり$f^{-1}((a,∞))\in F$</li>
<li>任意の$a\in R$に対し、$\lbrace x\in X| f(x)\geqq a\rbrace \in F$。つまり$f^{-1}([a,∞))\in F$</li>
<li>任意の$a\in R$に対し、$\lbrace x\in X| f(x)&lt;a\rbrace \in F$。つまり$f^{-1}((-∞,a))\in F$</li>
<li>任意の$a\in R$に対し、$\lbrace x\in X| f(x)\leqq a\rbrace \in F$。つまり$f^{-1}((-∞,a])\in F$</li>
</ol>
<h2 id="%E7%A2%BA%E7%8E%87%E3%81%AE%E8%A1%A8%E8%A8%98%E6%96%B9%E6%B3%95">確率の表記方法</h2>
<p>確率変数を用いたよく使われる確率の表記方法を紹介する。$(Ω,F,P)$なる確率空間と確率変数Xを考える。</p>
<p>$$
\begin{aligned}
&amp;P(X=x_i):=P(X^{-1}(\lbrace x_i\rbrace))\cr
&amp;P(X\in A):=P(X^{-1}(A))\cr
&amp;P(a\leqq X\leqq b):=P(X^{-1}([a,b]))
\end{aligned}
$$</p>
<h2 id="%E7%A2%BA%E7%8E%87%E5%A4%89%E6%95%B0%E3%81%8B%E3%82%89%E7%94%9F%E6%88%90%E3%81%95%E3%82%8C%E3%82%8B%CF%83%E5%8A%A0%E6%B3%95%E6%97%8F">確率変数から生成されるσ加法族</h2>
<p>$(Ω,F,P)$なる確率空間と$(R^d ,B(R^d))$なる測度空間を考える。まず、確率変数$X:Ω→R^d$は可測関数の条件より任意の$B\in B(R^d)$に対し
$$
X^{-1}(B)=\lbrace x\in Ω| f(x)\in B^d\rbrace \in F
$$
の性質を満たす。よって逆に確率変数$X$が与えられたとき
$$
σ(X):=\lbrace X^{-1}(B)| B \in B(R^d)\rbrace
$$
と定義すると$σ(X)$はσ加法族になる。証明は逆像の性質とσ加法族の性質を用いれば簡単にできる。よって <strong>確率変数Xで記述される事象は$σ(X)$で最小である。</strong></p>
<h2 id="%E6%9D%A1%E4%BB%B6%E4%BB%98%E7%A2%BA%E7%8E%87">条件付確率</h2>
<p>$(Ω,F,P)$なる確率空間に対し、ある事象Bを条件づけたときの、事象Aの <strong>条件付き確率</strong> $P(A|B)$は
$$
P(A|B)=\frac{P(A\cap B)}{P(B)}
$$
と定義される。ただし、$P(B)&gt;0$</p>
<p>$P(A|B)$の直感的な意味は、事象Bが起きるものとした時の事象Aが起こる確率となる。</p>
<p>また、実際に計算すると、$(Ω,F,P)$における条件付き確率$P(\cdot|B)$は確率測度となっているため$(Ω,F,P(\cdot|B))$の期待値も当然同じ式で求めることが出来る。</p>
<h2 id="%E3%83%99%E3%82%A4%E3%82%BA%E3%81%AE%E5%AE%9A%E7%90%86%E3%81%A8%E7%8B%AC%E7%AB%8B">ベイズの定理と独立</h2>
<p>条件付き確率の定義より以下の定理が成り立つ。
$$
P(B|A)=\frac{P(A|B)}{P(A)}P(B)
$$</p>
<p>この定理は以下の意味で重要である。</p>
<ul>
<li>P(B)は事象Aが起きる前の事象Bの確率(事前確率)</li>
<li>P(B|A)は事象Aが起きた後での事象Bの確率(事後確率)</li>
</ul>
<p>と見ることが出来る。また、$Ω$の直和分割$B_1,\cdots B_n\in F$とすると$P(A)=\sum_{i=1}^nP(B_i)P(A|B_i)$なので
$$
P(B_j|A)=\frac{P(B_j)P(A|B_j)}{P(A)}=\frac{P(B_j)P(A|B_j)}{\sum_{i=1}^nP(B_i)P(A|B_i)}
$$</p>
<p>また、以下の式が成り立つ時、事象AとBは独立であるという。(P(B)&gt;0とすると)</p>
<p>$$
P(A|B)=P(A)	\Leftrightarrow P(A\cap B)=P(A)P(B)
$$</p>
<p>が成り立つ時である。これは事象Bが起きたのを知っても事象Aの確率(事後確率)が変化しないという=事象Aと事象Bは独立している意味になる。</p>
<h2 id="%E7%A2%BA%E7%8E%87%E5%A4%89%E6%95%B0%E3%81%AE%E7%8B%AC%E7%AB%8B%E6%80%A7">確率変数の独立性</h2>
<p>確率変数$X,Y$に対し$σ(X),σ(Y)$の元(つまり事象)$X_σ\in σ(X),Y_σ\in σ(Y)$が独立ならば確率変数$X,Y$は独立であるという。言葉だけではわかりにくいので数式と同値な条件をいくつか示す。</p>
<ul>
<li>確率変数$X,Y$が独立</li>
<li>任意の$X_σ\in σ(X),Y_σ\in σ(Y)$が独立</li>
<li>任意の$B\in B(R)$に対し、$P(X^{-1}(B)\cap Y^{-1}(B))=P(X^{-1}(B))P(Y^{-1}(B))$</li>
<li>任意の$x,y\in R$に対し、$P_{X,Y}(x,y)=P_X(x)P_Y(y)$</li>
<li>任意の$x,y\in R$に対し、$F_{X,Y}(x,y)=F_X(x)F_Y(y)$</li>
<li>任意の$x,y\in R$に対し、$f_{X,Y}(x,y)=f_X(x)f_Y(y)$</li>
<li>全てのボレル可測 <strong>有界</strong> 関数f,gについて以下の式が成り立つ。
$$
E(f(X)g(Y))=E(f(X))E(g(X))
$$</li>
</ul>
<p>また、確率変数$X,Y$が独立→$E[XY]=E[X]E[Y]$が成り立つ。逆は成り立たない。</p>
<h2 id="%E7%A2%BA%E7%8E%87%E5%88%86%E5%B8%83%E3%81%BE%E3%81%9F%E3%81%AF%E5%8D%98%E3%81%AB%E5%88%86%E5%B8%83">確率分布(または単に分布)</h2>
<p>$(Ω,F,P)$なる確率空間と$(R^d,B(R^d))$なる測度空間を考える。さらに(d次元)確率変数$X=(X_1,X_2,\cdots,X_d)$が定義されているとする。</p>
<p>ここで測度$P^X$を以下のように構成する。($P^X$は$P_X$と書かれる本もあり。)
$$
P^X:B(R^d)→[0,1] \quad P^X(B)=P(X\in B)=P(X^{-1}(B))
$$</p>
<p>とする。するとこれは測度の条件を満たすため測度となりさらに確率測度となる。この$P^X$は <strong>Xの確率分布</strong> 、または単に <strong>Xの分布</strong> という。なお、測度論の言葉を使うなら(自分の測度論のサイトには載せてないが)像測度という言葉に対応する。ちなみにディラック測度($δ_a(A)=1\quad(a\in A)$)なる測度を用いると$P^X$の表記が楽になることがある。</p>
<p>これによって$(Ω,F,P)$なる確率空間から確率変数$X:Ω→R^n$を用いて、$(R^d,B(R^d),P^X)$なる確率空間を定義できた。</p>
<p>これは <strong>確率変数がその値になる確率</strong> ということもできる。確率変数が取らない集合を確率分布に入れれば0になるためである。</p>
<h2 id="%E5%88%86%E5%B8%83%E9%96%A2%E6%95%B0%E5%90%8C%E6%99%82%E5%88%86%E5%B8%83%E9%96%A2%E6%95%B0%E5%91%A8%E8%BE%BA%E5%88%86%E5%B8%83%E9%96%A2%E6%95%B0">分布関数、同時分布関数、周辺分布関数</h2>
<p>$(Ω,F,P)$なる確率空間と$(R^d,B(R^d),P^X)$なる確率空間を考える。さらに(d次元)確率変数$X=(X_1,X_2,\cdots,X_d)$が定義されているとする。</p>
<p>ここで$x\in R^d$に対し、$F:R^d→[0,1]$を
$$
\begin{aligned}
F(x):&amp;=P^X((-∞,x_1]×\cdots ×(-∞,x_d])\cr
&amp;=P^X(\lbrace X\in R^n|X_1\leqq x_1,\cdots,X_n\leqq x_n\rbrace)
\end{aligned}
$$
とおく。この$F(x)$を <strong>Xの分布関数</strong> という。特に$d\geqq2$の時の$F(x)$を <strong>Xの同時分布関数</strong> という。</p>
<p>また、$X_i$に対する分布関数を <strong>X_iの分布関数</strong> という。</p>
<p>定義を見ると、$F(x)$は確率変数$X$が$X&lt;x$になる確率と見ることが出来る。このような見方が出来れば逆に確率変数$X$が$x$になる確率は$F(X)-F(X_-)$となるのは彰がだろろう。つまり分布関数が(右連続は前提として)不連続でないと$X=x$となる確率は0である。逆に不連続なら$X=x$となる確率は0ではないのも明らかだろう。</p>
<h2 id="%E5%88%86%E5%B8%83%E9%96%A2%E6%95%B0%E3%81%AE%E6%80%A7%E8%B3%AA">分布関数の性質</h2>
<ol>
<li>Fは単調非減少関数</li>
<li>$F(∞)=1$かつ$F(-∞)=0$</li>
<li>$F(x)$は右連続関数</li>
<li>$P(a&lt;X\leqq b)=F(b)-F(a)$、$P(a\leqq X\leqq b)=F(b)-F(a_-)$。ただし、$F(a_-)=lim_{x→-0+a}F(x)$</li>
<li>$F$の不連続点はたかだか可算個</li>
</ol>
<p>要はルベーグ-スティルチェス測度を$P$とした時の$F$かな？(裏が取れたら追記)</p>
<h2 id="%E9%9B%A2%E6%95%A3%E5%9E%8B%E9%80%A3%E7%B6%9A%E5%9E%8B%E5%AF%86%E5%BA%A6%E9%96%A2%E6%95%B0">離散型、連続型、密度関数</h2>
<p>$1_A(x)=1\quad(x\in A),0\quad(OtherWise)$なる関数を <strong>定義関数</strong> という。また、定義より直ちに$1_{\varnothing}(x)=0$となることも念頭に置こう。</p>
<p>$p(a):=P(X=a)$なる関数$p:A→[0,1]$を <strong>確率関数</strong> と呼ぶ。または$f_x(a):=P(X=a)$と書いて <strong>確率質量関数</strong> と呼ばれる。</p>
<p>d次元ベクトル$x,y$が$x\leqq y$とは各$x_i,y_i$に対し、$x_i\leqq y_i$が成り立つとする。</p>
<p>たかだか可算な集合$A\subset R^d$に対し、$P(X\in A)=1$が成り立つとき、 <strong>Xは離散型</strong> という。つまり高々可算個の1点集合の確率変数の確率の和が1になるということである。数式にすると$\sum_{a\in A}p(a)=1$のAが高々可算可算であると言っている。また、 <strong>分布関数の取る値が高々可算個(ならば→不連続(逆は成り立たない))</strong> と言ってもいい。$A$を高々可算個とした場合$A$の任意の元に$N$でナンバリング出来るのでそれくぉ$a_i$とする。この時分布関数は以下のように書ける。
$$
\begin{aligned}
F(x)&amp;=\sum_{i:a_i\leqq x}P(X=a_i)=\sum_{i=1}^∞p(a_i)1_{\lbrace b|a_i\leqq b\leqq x\rbrace}(x)\cr
&amp;=\sum_{i:a_i\leqq x}P^X(\lbrace a_i\rbrace)
\end{aligned}
$$
ここで$1_{\lbrace b|a_i\leqq b\leqq x\rbrace}(x)$は$x\leqq a_i$ならば$1_{\varnothing}(x)$となるため常に0となり左辺と等しいのは分かるだろう。さらに確率分布$P^X$も
$$
P^X(B)=\sum_{a_i\in A}p(a_i)δ_{a_i}(B)
$$
となる。よって離散型だと確率(質量)関数$p(x)$が重要になる。</p>
<p>また、分布関数$F$が$R^d$上連続の時 <strong>Xは連続型</strong> という。特に$x\in R^d$に対し非負関数$f(x)$、ただし$\int_{R^d}f(x)dx=1$とする。これを用いて
$$
F(x)=\int_{(-∞,x_1]×\cdots ×(-∞,x_d]}f(z)dz=\int_{R^d}f(z)1_{\lbrace z\leqq x\rbrace}dz
$$
と書けるとき、 <strong>Fは絶対連続型</strong> といい、 <strong>fを(確率変数Xの分布関数Fの)確率密度関数</strong> または単に <strong>Xの密度関数</strong> という。</p>
<h2 id="%E6%A7%98%E3%81%AA%E5%AE%9A%E7%90%86">様々な定理</h2>
<p>以下&quot;測度と積分 著ツァピンンスキ訳二宮&quot;より抜粋。証明等が知りたかったらこちらを見てください。</p>
<ul>
<li>確率変数X:Ω→Rがある時、$g(x)$を可積分関数とすると以下が成り立つ。
$$
\int_Ωg(X(ω))dP(ω)=\int_Rg(x)dP_X(x)
$$</li>
<li>$R^n$上の$P_X$が絶対連続で(つまり任意の可測集合$B$について、非負可積分関数$f_X$(密度)を用いて$P_X(B)=\int_Bf_Xdm$と書けるとき)$g(x):R^n→R$が$P_X$を測度としたとき$g(x)$を可積分関数とすると以下が成り立つ。
$$
\int_{R^n}f_X(x)g(x)dx=\int_{R^n}g(x)dP_X(x)\quad(=\int_Ωg(X(ω))dP(ω))
$$</li>
<li>変数変換後の密度、確率変数$Y=Φ(X)$は関数$Φ$が微分可能で広義単調増加または減少ならば$Y$の密度関数$f_Y$は
$$
f_Y(y)=f_X(Φ^{-1}(y))|\frac{d}{dy}Φ^{-1}(y)|
$$</li>
</ul>
<h2 id="%E7%A2%BA%E7%8E%87%E5%A4%89%E6%95%B0%E7%A2%BA%E7%8E%87%E5%88%86%E5%B8%83%E5%88%86%E5%B8%83%E9%96%A2%E6%95%B0%E3%81%AE%E9%96%A2%E4%BF%82">確率変数、確率分布、分布関数の関係</h2>
<p>今までの流れを整理する。</p>
<ul>
<li>$(Ω,F,P)$なる確率空間がまず与えられている。</li>
<li>さらにそこに$X:Ω→R^d$なる確率変数(可測関数)を定義する。</li>
<li>すると$P^X$なる$X$の分布($(R^d,B(R^d)$の確率測度)が求まる。つまり$(R^d,B(R^d),P^X)$なる確率空間が導ける。</li>
<li>さらにそれ($P^X$)を用いると$X$の分布関数$F(x)$が求まる。 分布関数の取る値がたかだか可算個なら離散型、全ての点で連続なら連続型である。</li>
<li>ただし、場合によっては分布関数の取る値が非可算個なのに全ての点では連続にならないケースももちろんあるだろう。これは混合分布と呼ばれる。</li>
</ul>
<p>となる。混合型になる例を一つ上げる。</p>
<p>今、車がA市にいる。午後0時から午後1時の間をランダムに出発する。車は25km離れたB市に時速50kmで向かったとする。ここで午後1時置ける車のB市からの距離の分布関数を求めよ。</p>
<p>まず、出発時間$ω\in[0,1]$に対し、確率変数$X:ω→R$を午後1時置ける車のB市からの距離とする。すると問題の設定より明らかに
$$
P^X(B)=\frac{1}{2}δ_0(B)+\frac{1}{2}\frac{μ_{[0,25]}(B)}{25}
$$
となる。ここで$δ_0(B)$は$0\in B$の時だけ$1$になりそれ以外は$0$となる関数(ディラック測度)である。$μ_{[0,25]}(B)$は制限されたルベーグ測度$μ_[0,25]:=μ(B\cap[0,25 ])$である。つまり最大で25である。よって分布関数は画像のものになる。</p>
<p><img src="https://yukimaru77.github.io/practice/測度論的確率論/混合分布.jpg" alt="画像がなかった時の代替テキスト"></p>
<h2 id="%E6%9C%9F%E5%BE%85%E5%80%A4">期待値</h2>
<p>$(Ω,F,P)$なる確率空間と$X:Ω→R$なる確率変数を考える。確率変数$X$が$P-$可積分である時
$$
E[X]:=\int_ΩX(w)P(dw)\quad(=\int_R xdP_x)
$$
と書いて、$E[X]$を$X$の期待値という。$X$が$P-$可積分出ない時には期待値を持たないという。なお、$B\in F$なる$B$に積分範囲を制限した期待値を
$$
E[X;B]=E[1_BX]=\int_Ω1_B(w)X(w)P(dw)
$$
と書く。</p>
<h2 id="%E8%A4%87%E7%B4%A0%E9%96%A2%E6%95%B0%E3%81%AE%E7%A9%8D%E5%88%86">複素関数の積分</h2>
<p>実確率変数$X,Y$に対して$Z=X+iY$とおく。これの積分を
$$
\int ZdP=\int XdP+i\int YdP
$$
と定義する。すると積分の線形性や優収束定理や以下の性質が成り立つ。
$$
|\int ZdP|\leqq \int|Z|dP
$$</p>
<h2 id="lp%E7%A9%BA%E9%96%93">$L^P$空間</h2>
<p>少し関数空間の話をする。</p>
<p>可測関数$f:E→C$の集合$L$を考える。ここでさらにそれの部分集合として$(\int_E|f|^pdm)^\frac{1}{p}$が収束する集合を考える。これを$L^P(E)$空間という。厳密にいえばさらに$f～g:=f=g(a.e.)$なる同値関係で分ける。があまり気にしなくてもいたるところで等しい関数は同一視すると思っておけばいい。</p>
<p>さて、ここで関数の可積分性はc倍及び可算に関して閉じているので$L^1(E)$は <strong>ベクトル空間</strong> でありさらに実は$L^P(E)$空間もベクトル空間である。よって体を$RやC$とおくとノルムの定義を試みることが出来る。ここでノルムを
$$
||f||_p:=(\int_E|f|^pdm)^\frac{1}{p}
$$
と定義する。するとノルムの公理の要請より$||f||_p=0\Leftrightarrow f=0$を満たす必要があるが我々はいたるところで等しい関数は同一視する立場を取る(厳密にいうならノルムを同値類に対し定義する)のでこれを満たすとすると先ほどのノルムの定義はノルムの公理を満たす。よって$(L^P(E),||f||_p)$は <strong>ノルム空間</strong> である。</p>
<p>さらに定理として以下が成り立つ。</p>
<ul>
<li>$1&lt;p&lt;∞$の時$L^P$空間は <strong>完備</strong> である。つまりバナッハ空間である。</li>
<li>ルベーグ測度$μ(E)$が有限ならば$1\leqq p\leqq q\leqq ∞$について$L^q(E)\subset L^p(E)$である。</li>
</ul>
<p>ここで完備とは任意のコーシー列の収束先がその集合に含まれるようなことである。例えば$Q$において$a_1=3.1,a_2=3.14,a_3=3.141,\cdots$とするとコーシー列の収束値$π$は$π\in Q$ではないのでQ完備でない。</p>
<h2 id="%E9%96%89%E9%83%A8%E5%88%86%E7%A9%BA%E9%96%93">閉部分空間</h2>
<p>ノルム空間$(x,||\cdot||)$に対し、部分空間$y$が <strong>閉部分空間</strong> であるとはノルムに関して閉じている部分空間を言う。つまり$y$上の点列$\lbrace y_n\rbrace_{n\in N}$と$u\in X$に対し
$$
\lim_{n→∞}||y_n-u||=0
$$
を満たすとき、$u\in y$になる時を言う。つまり$y$上のコーシー列が収束列になることを言う。つまり完備であることを要請している。</p>
<p>閉部分空間に対して以下の定理が成り立つ。</p>
<ul>
<li>バナッハ空間$X$に対し部分空間$y$が完備である事と閉部分空間なことは同値</li>
<li>ヒルベルト空間$X$に対し部分空間$y$が完備である事と(内積によるノルムに対して)閉部分空間なことは同値</li>
</ul>
<p>当たり前に見えるのは自分だけだろうか。。</p>
<h2 id="%E9%83%A8%E5%88%86%E7%A9%BA%E9%96%93%E3%81%AE%E7%9B%B4%E5%92%8C">部分空間の直和</h2>
<p>ベクトル空間の部分集合がベクトル空間になる場合、 <strong>部分空間</strong> という。</p>
<p>あるベクトル空間$V$に対し、部分空間$W_1,W_2$が
$$
V=W_1\cup W_2,W_1\cap W_2=\varnothing
$$
を満たすとき、$W_1\cup W_2$を$W_1+W_2$または$W_1⊕W_2$を <strong>直和</strong> といい$V$の直和という。同値な言い換えとして$V$の直和とは</p>
<ol>
<li>$W_1\cap W_2=\varnothing$</li>
<li><strong>$V$の任意の要素が、$W_1,W_2$の要素の和として一意に表される</strong></li>
</ol>
<p>とも言い換えられる。$n$個の場合も同じである。$V$の直和は以下の性質を見たす。
$$
dim(W_1+W_2)=dim(W_1)+dim(W_2)
$$</p>
<p>なお、一般には(つまり直和でない場合)
$$
dim(W_1+W_2)=dim(W_1)+dim(W_2)-dim(W_1\cap W_2)
$$
となる。</p>
<p>直和の例としてはベクトル空間$R^2$は$W_1$を$(x,0)$で表せれる$R^2$の元の集合、$W_2$を$(x,x)$で表せれる$R^2$の元の集合とすれば直和になる。
$$
\begin{aligned}
&amp;W_1=\lbrace x=(x_1,x_2)\in R^2 | x_2=0 \rbrace \cr
&amp;W_2=\lbrace x=(x_1,x_2)\in R^2 | x_1=x_2 \rbrace
\end{aligned}
$$
とすればこれは直和となる。</p>
<h2 id="%E5%B0%84%E5%BD%B1%E5%B0%84%E5%BD%B1%E4%BD%9C%E7%94%A8%E7%B4%A0">射影(射影作用素)</h2>
<p>$V$の直和$W_1+W_2$を考える。ここで直和なので$v\in V$は$w_1\in W_1,w_2\in W_2$を用いて$v=w_1+w_2$と一意に表せる。ここで写像$P_1,P_2$を
$$
\begin{aligned}
&amp;P_1:V→W_1,P_1(v)=w_1(ただしv=w_1+w_2)\cr
&amp;P_2:V→W_2,P_2(v)=w_2(ただしv=w_1+w_2)
\end{aligned}
$$
とする。これをそれぞれ、部分空間$W_1,W_2$への <strong>射影</strong> という。</p>
<h2 id="%E9%83%A8%E5%88%86%E7%A9%BA%E9%96%93%E3%81%AE%E7%9B%B4%E4%BA%A4%E3%81%A8%E7%9B%B4%E4%BA%A4%E8%A3%9C%E7%A9%BA%E9%96%93">部分空間の直交と直交補空間</h2>
<p>部分空間$W_1,W_2$が直交しているとは$w_1\in W_1,w_2\in W_2$に対し
$$
&lt;w_1,w_2&gt;=0
$$
が成り立つことを言う。さらにこのような$W_2$を$W_1^\bot$と表し <strong>直交補空間</strong> という。</p>
<h2 id="l2%E7%A9%BA%E9%96%93">$L^2$空間</h2>
<p>特に$L^2$を考えてみよう。ここで
$$
(f,g)=\int_Ef\bar gdm
$$
とおくと$(f,g)$は内積の公理を満たすため内積となる。さらに
$$
\sqrt{(f,f)}=\sqrt{\int_Ef\bar fdm}=||f||_2
$$
となりノルムを導ける。さらに内積から導かれたノルム(自然に導かれたノルム)は平行四辺則
$$
||h_1+h_2||^2+||h_1-h_2||^2=2(||h_1||^2+||h_2||^2)
$$
などを満たす。さらに内積が定義できるということは各元の角度なるもの及び直行の概念を定義できることを意味する。これを内積空間という。さらに内積空間が完備の時、 <strong>ヒルベルト空間</strong> という。</p>
<p>ヒルベルト空間において以下の定理が成り立つ。</p>
<ul>
<li>Kをヒルベルト空間Hの閉部分空間(完備部分空間)とする。すると$K^\bot$が一意に存在し$H=K+K^\bot$なる直和になる。さらにそれらへの直交射影は一意に定まり、$||h-k||$は最小となる。</li>
<li>正規直交基底を作ることが出来る。例えば、$L^2[-π,π]$ならばフーリエ級数表現へと導かれる。</li>
</ul>
<h2 id="%E3%83%A2%E3%83%BC%E3%83%A1%E3%83%B3%E3%83%88">モーメント</h2>
<p>$n\in N$とする。ここで確率変数$X\in L^n(Ω)$の <strong>n次モーメント</strong> とは、
$$
E(X^n),n=1,2,\cdots
$$
と定義される。</p>
<p><strong>中心モーメント</strong> は$E(X)=μ$とおくと
$$
E((X-μ)^n),n=1,2,\cdots
$$
と定義される。</p>
<p>モーメントは前章の定理より
$$
E(X^n)=\int x^ndP_X(x) \quad(=\int x^nf_X(x)dx)
$$
$$
E((X-μ)^n)=\int (x-μ)^ndP_X(x) \quad(=\int (x-μ)^nf_X(x)dx)
$$</p>
<h2 id="%E5%88%86%E6%95%A3%E6%A8%99%E6%BA%96%E5%81%8F%E5%B7%AE">分散、標準偏差</h2>
<p>確率変数の <strong>分散</strong> とは二次の中心モーメント
$$
Var(X)=E((X-E(X))^2)
$$
と定義される。つまり明らかに$E(X)=μ$とおくと
$$
Var(X)=E((X-E(X))^2)=E(X^2-2μX+μ^2)=E(X^2)-2μE(X)+μ^2=E(X^2)-μ^2
$$
が成り立つ。これは <strong>2次の中心モーメントは1次、2次モーメントで決まる</strong> 事を表している。さらに一般化して <strong>$n$次の中心モーメントは$k\leqq n$次モーメントで決まる</strong> 。逆に <strong>$n$次のモーメントは$k\leqq n$次中心モーメントで決まる</strong>
も成り立つ。</p>
<h2 id="%E7%89%B9%E6%80%A7%E9%96%A2%E6%95%B0">特性関数</h2>
<p>確率変数$X$に対し、$Φ_X(t)=E(e^{iXt})$と定義する。これを特性関数という。$Φ_X(t)$が$t$で$k$回連続微分可能ならば以下の定理が成り立つ。
$$
E(X^k)=(\frac{1}{i})^k\frac{d^kΦ_X}{dt^k}(0)
$$
もし逆に$X$が有限の$k$次モーメントを持つなら$Φ_X(t)$は$t$で$k$回連続微分可能となる。</p>
<h2 id="%E4%B8%AD%E5%BF%83%E5%8C%96%E3%81%97%E3%81%9F%E7%A2%BA%E7%8E%87%E5%A4%89%E6%95%B0%E5%85%B1%E5%88%86%E6%95%A3%E7%9B%B8%E9%96%A2%E4%BF%82%E6%95%B0">中心化した確率変数、共分散、相関係数</h2>
<p>確率変数$X_c$を
$$
X_c:=X-E(X)
$$
とおく。この$X_c$を <strong>中心化した確率変数</strong> と呼ぶ。明らかにこれは$E(X_c)=0$となる。</p>
<p>$E(XY)=\int_ΩXYdP$よりこれは二乗可積分な確率変数の空間$L^2(Ω,R)$の内積$&lt;X,Y&gt;$そのものである。</p>
<p><strong>共分散</strong> $Cov(X,Y)$を
$$
\begin{aligned}
Cov(X,Y):&amp;=&lt;X_c,Y_c&gt; \cr
&amp;=E((X-E(X))(Y-E(Y)))\cr
&amp;=E(XY)-E(X)E(Y)
\end{aligned}
$$
と定義する。相関係数$ρ_{X,Y}$をさらに角度の予言として定義する。つまり
$$
ρ_{X,Y}=\frac{(X_c,Y_c)}{||X||_2||Y||_2}=\frac{Cov(X,Y)}{||X||_2||Y||_2}
$$
となる。さらに$ρ=0$即ち$Cov(X,Y)=0$を <strong>無相関</strong> と呼ぶ。無相関ならば共分散の式より$E(XY)=E(X)E(Y)$が成り立つ。ここで$E(XY)=E(X)E(Y)$ならば無相関でもあるので結局以下は同値である。</p>
<ul>
<li>X,Yは無相関</li>
<li>$ρ=0$即ち$Cov(X,Y)=0$</li>
<li>$E(XY)=E(X)E(Y)$</li>
</ul>
<p>また、確率変数$X,Y$が独立ならば無相関であるが、確率変数$X,Y$が無相関ならば独立は成り立たない。</p>
<h2 id="%E5%B0%91%E3%81%97%E7%9B%B4%E7%A9%8D%E6%B8%AC%E5%BA%A6%E3%81%AE%E5%BE%A9%E7%BF%92">少し直積測度の復習</h2>
<p>以下自分のサイトから引用。</p>
<h2 id="%E7%9B%B4%E7%A9%8D%E6%B8%AC%E5%BA%A6%E7%A9%BA%E9%96%93">直積測度空間</h2>
<p>2つの測度空間$(X,F,μ)、(Y,G,v)$に対し$f\in F、g\in G$の直積$f×g\subset X×Y$全体のなす集合が生成するシグマ加法族を$F×G$とおく。つまり
$$
F×G:=σ(\lbrace f×g|f\in F,g\in G\rbrace)
$$
とおく。同値な表現として
$$
F×G:=σ(\lbrace f×Y|f\in F\rbrace\cup\lbrace X×g|g\in G\rbrace)
$$
や
$$
Pr_1(ω_1,ω_2)=ω_1,Pr_2(ω_1,ω_2)=ω_2
$$
なる射影が両方可測になるような最小のシグマ加法族を$F×G$とおく。などがある。</p>
<p>さらに測度$m=μ×v$を
$$
m(F×G)=μ(F)v(G)
$$
となる測度と置く。この時$(X×Y,F×G,μ×v)$を直積測度空間という。</p>
<p>なお、直積測度$μ×v$は存在するか、存在しても一意なのか自明でないが、$μ、v$がともに <strong>σ-有限性なら一意に存在する。</strong> なお、 <strong>確率測度やルベーグ測度はσ-有限性を持つ。</strong></p>
<p>また、(後述する切り口の記号を用いて)、$Q\in F×G$とおくと
$$
(μ×v)(Q)=\int_Xv(Q_x)μ(dx)\qquad (=\int_Yμ(Q_y)v(dy))
$$
となる。(熊谷P171)</p>
<h2 id="%E9%9B%86%E5%90%88%E5%8F%8A%E3%81%B3%E9%96%A2%E6%95%B0%E3%81%AE%E5%88%87%E3%82%8A%E5%8F%A3%E3%81%AE%E5%AE%9A%E7%BE%A9%E3%81%A8%E5%8F%AF%E6%B8%AC%E6%80%A7">集合及び関数の切り口の定義と可測性</h2>
<p>σ有限の測度空間の直積からなる直積測度空間$(X×Y,F×G,μ×v)$において、$E\subset X×Y$を考える。$x\in X$に対して$E_x$を
$$
E_x=\lbrace y\in Y|(x,y) \in E\rbrace\quad (\subset Y)
$$
と定義する。これを$x\in X$によるEの切り口(切断)という。</p>
<p>ここで定理として、$E$が$F×G$可測なら、$E_x(\subset Y)$は$G$可測となり、$E_y(\subset X)$は$F$可測となる。</p>
<p>また関数の切り口も考える。$f(x,y):X×Y→R$を考える。$A\in X$に対し(今回は分かりやすくするためにAと書いたがxとするのが普通)、$f_A(y)$を
$$
f_A(y):Y→R \quad f_A(y)=f(A,y)
$$
と定義する。これを切り口関数といい、$f(x,y)$が可測関数なら$f_x(y)$は$G$可測、$f_y(x)$は$F$可測となる。</p>
<h2 id="%E3%83%95%E3%83%93%E3%83%8B-%E3%83%88%E3%83%8D%E3%83%AA%E3%81%AE%E5%AE%9A%E7%90%86">フビニ-トネリの定理</h2>
<p>フビニの定理とトネリの定理のいいとこどりをします。中にはこれをフビニの定理と言っている場合もあります。</p>
<p>σ有限の測度空間の直積からなる直積測度空間$(X×Y,F×G,μ×v)$において、$f(x,y):X×Y→R$が可測関数なら
$$
\begin{aligned}
\int_{X×Y}&amp;|f(x,y)|μ×v(dx,dy)\cr
&amp;=\int_x(\int_Y|f(x,y)|v(dy))μ(dx)\cr
&amp;=\int_x(\int_X|f(x,y)|μ(dx))μ(dx)
\end{aligned}
$$
が成り立つ(トネリの定理より)。さらにこの値が有限なら(ここからはフビニの定理)
$$
g(y)=\int_Xf(x,y)μ(dx)、h(x)=\int_Yf(x,y)v(dy)、
$$
はそれぞれ非負で$G$可測、$F$可測となる。さらに積分結果は
$$
\begin{aligned}
\int_{X×Y}&amp;f(x,y)μ×v(dx,dy)\cr
&amp;=\int_xh(x)μ(dx)=\int_x(\int_Yf(x,y)v(dy))μ(dx)\cr
&amp;=\int_Yg(y)v(dy)=\int_x(\int_Xf(x,y)μ(dx))μ(dx)
\end{aligned}
$$
が成り立つ。</p>
<h2 id="%E7%9B%B4%E7%A9%8D%E6%B8%AC%E5%BA%A6%E7%A9%BA%E9%96%93%E3%81%AE%E6%80%A7%E8%B3%AA">直積測度空間の性質</h2>
<p>確率空間$(Ω_1,F_1,P_1),(Ω_2,F_2,P_2)$と直積測度空間$(Ω,F,P)$を考える。すると以下のの定理が成り立つ。</p>
<ul>
<li>$P(A_1×A_2)=P(A_1)P(A_2)$</li>
<li>$P(A)=\int_{Ω_2}P_1(A_{ω_2})dP_2(ω_2)=\int_{Ω_1}P_2(A_{ω_1})dP_1(ω_1)$</li>
<li>$f:Ω→R$が非負可測関数なら∞に関しても含めて
$$
\int_Ωf(ω_1,ω_2)dP(ω)=\int_{Ω_1}(\int_{Ω_2}f(ω_1,ω_2)dP_2(ω_2)dP_1)(ω_1)=\int_{Ω_2}(\int_{Ω_1}f(ω_1,ω_2)dP_1(ω_1)dP_2)(ω_2)
$$</li>
</ul>
<h2 id="%E7%B5%90%E5%90%88%E5%88%86%E5%B8%83">結合分布</h2>
<p>$X,Y$を確率空間$(Ω,F,P)$上の確率変数とする。ここで$(X,Y):Ω→R^2$なる確率変数(以後確率ベクトルという)を考える。この時の確率分布は
$$
P_{(X,Y)}(B)=P((X,Y)\in B(R^2))
$$
となりこれを$X,Y$の <strong>結合分布</strong> という。さらに
$$
P_X(B)=P_{(X,Y)}(B×R),P_Y(B)=P_{(X,Y)}(R×B)
$$
となりこのような時の$P_XやP_Y$を <strong>周辺分布</strong> と呼ぶ。また、確率ベクトル$(X,Y)$が確率密度を持つとき、それを <strong>結合密度</strong> と呼び、結合密度が存在するなら以下の定理が成り立つ。</p>
<ul>
<li>$X,Y$に対しても密度$f_X(x),f_Y(y)$が存在して以下になる。
$$
f_X(x)=\int_Rf_{X,Y}(x,y)dy,\quad f_Y(y)=\int_Rf_{X,Y}(x,y)dx
$$</li>
<li>$X+Y$に対し密度$f_{X+Y}$は以下の式となる。
$$
f_{X+Y}(z)=\int_Rf_{X,Y}(x,z-x)dx
$$</li>
</ul>
<p>特に確率変数$X,Y$が独立なら$f_{X,Y}=f_Xf_Y$なので
$$
f_{X+Y}(z)=\int_Rf_{X}(x)f_{Y}(z-x)dx
$$
これは合成積$f<em>g:=\int_{-∞}^∞f(t)g(x-t)dt$そのものなので$f_{X+Y}(z)=(f_X</em>f_Y)(z)$となり確率分布はそれのボレル集合での積分なので$P_{X+Y}(B)=(P_X*P_Y)(B)$</p>
<h2 id="%E6%9D%A1%E4%BB%B6%E4%BB%98%E7%A2%BA%E7%8E%87%E3%81%A8%E6%9D%A1%E4%BB%B6%E4%BB%98%E5%AF%86%E5%BA%A6%E3%81%A8%22%E5%BD%A2%E5%BC%8F%E7%9A%84%22%E3%81%AA%E6%9D%A1%E4%BB%B6%E4%BB%98%E6%9C%9F%E5%BE%85%E5%80%A4">条件付確率と条件付密度と&quot;形式的&quot;な条件付期待値</h2>
<p>二つの確率変数$X,Y$が結合密度を持つ場合は考える。ボレル集合を$A,B$とし$dm_n$を$n$次元ルベーグ測度とし、意味が明確な時はルベーグ測度dmをdxなどと書く。
$$
\begin{aligned}
P(Y\in B|X\in A)&amp;=\frac{P(X\in A,Y\in B)}{P(X\in A)}\cr
&amp;=\frac{\int_{A×B}f_{(X,Y)(x,y)dm_2(x,y)}}{\int_Af_X(x)dm(x)}\cr
&amp;=\frac{1}{\int_Af_X(x)dx}\int_B\int_A f_{(X,Y)}(x,y) dxdy\cr
&amp;=\int_B  \frac{\int_A f_{(X,Y)}(x,y) dx}{\int_Af_X(x)dx}dy
\end{aligned}
$$</p>
<p>ここで$P(Y\in B|X\in A)$は確率の公理を満たす立派な確率なのでこれにも密度が存在するなら任意のボレル集合$B$に対して
$$
P(Y\in B|X\in A)=\int_B h(y|X\in A)dy
$$
となるため見比べて
$$
h(y|X\in A)=\frac{\int_A f_{(X,Y)}(x,y) dx}{\int_Af_X(x)dx}
$$
ここで$X=\lbrace a\rbrace$と置けば <strong>条件付確率密度</strong> $h(y|X=a)$は
$$
h(y|X=a)=\frac{f_{(X,Y)}(a,y)}{f_X(a)}
$$
となる。よって$X=a$が与えられたときの <strong>条件付確率</strong> は
$$
P(Y\in B|X=a)=\int_Bh(y|a)dy
$$
と表せられ、$X=a$が与えられたときの条件付期待値は
$$
E(Y|X=a)=\int_Ryh(y|a)dy
$$
と定義する。ここで$X=a$を$ω$の関数だと思えば
$$
E(Y|X)(ω):=E(Y|X(ω))=\int_Ryh(y|X(ω))dy
$$
と表すことが出来、これは$σ(X)$-可測関数となっている。よって$E(Y|X)(ω)$は確率変数である。さらに以下の性質
$$
\int_{R^n}f_X(x)g(x)dx=\int_{R^n}g(x)dP_X(x)\quad(=\int_Ωg(X(ω))dP(ω))
$$
に注意すれば
$$
\begin{aligned}
E(E(Y|X(ω)))&amp;=\int_ΩE(Y|X(ω))dP\cr
&amp;=\int_RE(Y|x)f_X(x)dx\cr
&amp;=\int_R\int_Ryh(y|x)dyf_X(x)dx\cr
&amp;=\int_R\int_Ryf_{(X,Y)}(x,y)dxdy\cr
&amp;=\int_Ryf_Y(y)dy=E(Y)
\end{aligned}
$$
となり、より一般には任意の$A\inσ(X)$に対して
$$
\int_AE(Y|X)dP=\int_AYdP
$$
となる。よってこれは <strong>$A\inσ(X)$なる$A$に制限した期待値においてE(Y|X)とYは値が等しい事を意味する、</strong> 後に再定義する条件付確率によると多分これは$E(Y|σ(X))$に等しい。ただしこれではあまり条件付期待値の意味がわからない、イメージしにくいだろうしそもそも結合密度ありきの定義になってしまう。ここでこれをより一般的に定義できる方法を模索し、さらにヒルベルト空間の直交射影を用いて条件付期待値の幾何学的な意味も肉付けする。</p>
<h2 id="%E7%B5%B6%E5%AF%BE%E9%80%A3%E7%B6%9A%E3%81%A8%E3%83%A9%E3%83%89%E3%83%B3-%E3%83%8B%E3%82%B3%E3%83%87%E3%82%A3%E3%83%A0%E3%81%AE%E5%AE%9A%E7%90%86">絶対連続とラドン-ニコディムの定理</h2>
<p>可測空間$(Ω,F)$のおいて、測度$v,m$が定義されているとする。任意の$A\in F$について
$$
m(A)=0ならばv(A)=0
$$
が成り立つとき、$v$は$m$に関して <strong>絶対連続</strong> といい$v&lt;&lt;m$の書く。ここで測度$m$と可測関数$f$に関する定理、$m(A)=0$ならば
$$
\int_Afdm=0
$$
よりもし、非負可積分関数$f$を用いて
$$
v(A)=\int_Afdm
$$
と表せられるのなら、$v$は$m$に関して絶対連続$v&lt;&lt;m$となる。</p>
<p>条件を少し加えて、この逆を主張するのがラドン-ニコディムの定理である。可測空間$(Ω,F)$のおいて、測度$v,m$がσ-有限測度であって$v$は$m$に関して絶対連続$v&lt;&lt;m$ならば全ての$A\in F$に対して
$$
v(A)=\int_Ahdm
$$
なる非負可積分関数$h$がいたるところで等しい関数を除いて <strong>一意に存在する。</strong>　また、この$h$を$\frac{dv}{dm}$と表記し、 <strong>ラドン-ニコディム微分</strong> という。</p>
<p>また、定理の拡張として可測空間$(Ω,F)$のおいて、測度$v$が有界な符号付測度で$m$がσ-有限測度であって$v$は$m$に関して絶対連続$v&lt;&lt;m$ならば全ての$A\in F$に対して$v&lt;&lt;m$ならば全ての$A\in F$に対して
$$
v(A)=\int_Afdm
$$
なる可積分関数$f$がいたるところで等しい関数を除いて <strong>一意に存在する。</strong></p>
<p>演算規則としては以下が成り立つ。なお、$λ&lt;&lt;μ,v&lt;&lt;μ$とする。</p>
<ul>
<li>$Φ=λ+μ$とすると$\frac{dΦ}{dμ}=\frac{dλ}{dμ}+\frac{dv}{dμ}$</li>
<li>$λ&lt;&lt;μ$ならば、$\frac{dλ}{dμ}=\frac{dv}{dμ}\frac{dλ}{dv}$</li>
</ul>
<h2 id="%E6%B8%AC%E5%BA%A6%E3%81%AE%E9%9B%86%E4%B8%AD%E7%89%B9%E7%95%B0%E6%B8%AC%E5%BA%A6%E3%81%A8%E3%83%AB%E3%83%99%E3%83%BC%E3%82%B0%E5%88%86%E8%A7%A3">測度の集中、特異測度とルベーグ分解</h2>
<p>測度$λ$はある$E\in F$と全ての$A\in F$に対し
$$
λ(A)=λ(A\cap E)
$$
となる時、$λ$は$E$ <strong>上に集中している</strong> という。同値な表現として$E\cap A=\varnothing$ならば$λ(F)=0$となる。もし完備な測度ならば$E^c$が最大の零集合であるとも同値だと思うし感覚としてはこれが一番重要ではとも思う。</p>
<p>ここで測度$μ,v$が互いに交わらない部分集合に集合しているとき$μ\bot v$とかいて <strong>互いに特異である</strong> あるいは <strong>特異測度</strong> という。</p>
<p>可測空間$(Ω,F)$において測度$μ,v$がσ-有限ならば$λ_a&lt;&lt;μ$かつ$λ_s\bot μ$となるような二つの測度$λ_a,λ_s$が一意に存在し$λ=λ_a+λ_s$となる。これを <strong>ルベーグ分解</strong> という。ラドン-ニコディムの定理を組み合わせれば即座に$λ(E)=\int_Ehdμ+λ_s(E)$となる。</p>
<h2 id="%E6%9D%A1%E4%BB%B6%E4%BB%98%E6%9C%9F%E5%BE%85%E5%80%A4%E3%81%B8%E3%81%AE%E5%89%8D%E7%9F%A5%E8%AD%98">条件付期待値への前知識</h2>
<p>確率空間$(Ω,F,P)$及び$(Ω,G,P)$を考える。ただし$G\subset F$であり、$(Ω,G,P)$の$P$は$(Ω,F,P)$の$P$の定義域を制限した写像とする。</p>
<p>ここで二乗可積分な$F-$可測実確率関数の空間を$L^2:=L^2(Ω,F,P)$と表し、二乗可積分な$G-$可測実確率関数の空間$L^2(G)$と表記する。ここで定義より明らかに$L^2(G)\subset L^2$かつ$L^2,L^2(G)$は完備である。よって直交補空間$L^2(G)^\bot$が存在し
$$
L^2=L^2(G)+L^2(G)^\bot
$$
である。ただし、&quot;+&quot;は直和という意味で使っている。さらに$L^2$の任意の元(つまり確率変数)を$X$とすると$Y\in L^2(G),Y'\in L^2(G)^\bot$を用いて
$$
X=Y+Y'
$$
と書ける。よって$L^2→L^2(G)$なる$X$の直交射影を$Y$とする。ここで、$X-Y$は$X-Y\in L^2(G)^\bot$であり、$L^2(G)$の任意の元を$Z$に対し直交するので
$$
&lt;X-Y,Z&gt;=\int_Ω (X-Y)ZdP=0
$$
が成り立つ。</p>
<p>特に$g\in G$に対し、
$$
\int_Ω|1_g(ω)|^2dP(ω)=\int_gdP=P(g)&lt;∞
$$
より$1_g\in L^2(G)$であるので上式の$Z$を$1_g$を代入しても
$$
&lt;X-Y,1_g&gt;=\int_Ω (X-Y)1_gdP=\int_g (X-Y)dP=0
$$
となる。変形して
$$
\int_g XdP=\int_g YdP
$$
となる。これが全ての$g\in G$に対し成り立つ。これは条件付確率密度で出した式と同じであり、しかも内積を含まない表現になっている。よって我々に$L^1$空間にも条件付期待値$Y$なるものを定義できるのではないかという希望を与えてくれる。</p>
<h2 id="%E6%9D%A1%E4%BB%B6%E4%BB%98%E6%9C%9F%E5%BE%85%E5%80%A4%E3%81%AE%E7%89%87%E9%B1%97">条件付期待値の片鱗</h2>
<p>ここで$X$の$L(G)$への直交射影$Y\in L(G)$は$||X-Y||_2$が最小のものとなっている。つまり$X$に一番近い$Y$となる。これは <strong>推定値として最良なのではないかという発想を自然に与えてくれる。</strong> また、</p>
<p>$$
\int_g XdP=\int_g YdP
$$
なる式は、条件付確率密度で定義した条件付期待値から導かれた定理と同じ結果である。以上の動機より以下のように条件付期待値の定義を改めてみよう。</p>
<p>$X$の$L^2(G)$への直交射影を$Y:=E[X|G]$と書いて$G$が与えられたときの$X$の条件付期待値と呼ぶ。ただしこの定義では、ヒルベルト空間による性質を用いているため$L^2$空間限定の定義となってしまう。しかし
$$
\int_g XdP=\int_g YdP
$$
の式は$L^1$でも考えることのできる(すなわち内積を含まない)式なのでここにより一般的な条件付期待値の片鱗を見出すことが出来る。</p>
<h2 id="%E6%9D%A1%E4%BB%B6%E4%BB%98%E6%9C%9F%E5%BE%85%E5%80%A4">条件付期待値</h2>
<p>さていよいよ条件付期待値の3回目の(再)定義に入る。今までの定義を復習しておこう。</p>
<ul>
<li>$E(Y|X)(ω):=\int_yyh(y|X(ω))f_Xdy$といった形で定義し、条件付確率密度を用いる方法。$E(Y|X)(ω)=E(Y|X=a)=E(Y|X(ω))$と書かれる事もあり、$E(Y|X)$は$σ(X)-$可測関数である。つまり確率変数である。$E(Y|X)$と$Y$は$σ(X)$の範囲の制限した期待値が等しい。つまり$A\inσ(X)$に対し、$\int_AE(Y|X)dP=\int_AYdP$となる。ここで$Y=E(Y|X)$ではないので注意。</li>
<li>$X→Y$が$L^2$から$L^2(G)$への直交射影とすると、その$Y$を用いて$Y=E[X|G]$と表記して条件付期待値を定義する方法。これも先ほどと同様に確率変数であり、$E(X|G)$と$X$は$G$の範囲の制限した期待値が等しい。</li>
</ul>
<p>問題点には以下のようなものが上がる。</p>
<ol>
<li>条件付確率密度による定義だと結合密度の存在が条件となってしまう。</li>
<li>$L^2$空間限定になってしまう。</li>
</ol>
<p>点がある。ここで条件付期待値の定義を以下のように定義し、その正当性をラドン-ニコディムの定理を用いて証明して終了する。確率空間$(V,F,P)$に対し確率変数$X\in L^1(F)$に対し$Y\in L^1(G)$が以下を満たすとき、$Y$を$E[X|G]$と書いて条件付期待値と呼ぶ。
$$
\int_g XdP=\int_g YdP
$$</p>
<p>以下は存在と一意性の証明。確率空間$(V,F,P)$と確率変数$X\in L^1(Ω,F,P)$に対し、$f\in F$に対し
$$
v(f)=\int_fXdP
$$
とすると$v$は有界測度となる。場合によっては符号付となる。定義より明らかに$v$は$P$に対して絶対連続となっている。二つの測度$v,P$の定義域を$(Ω,G)$に狭めてもこの測度の絶対連続性は変わらないためこれを$v_G,P_G$と書くことにするとやはり$v_G&lt;&lt;P_G$である。さらにこれらの$P$は$σ-$有限で$v_G$は有界な符号付測度なため拡張されたラドン-ニコディムの定理より確率変数$Y\in L^1(Ω,G,P_G)$に対し
$$
v_G(f)=\int_gYdP_G
$$
を満たすものがいたるところで等しいものを除いて一意に存在する。よって条件付期待値$Y$が存在しこれは
$$
\int_g XdP=\int_g YdP
$$
を満たす唯一のものである。</p>
<h2 id="%E6%9D%A1%E4%BB%B6%E4%BB%98%E6%9C%9F%E5%BE%85%E5%80%A4%E3%81%AE%E3%82%A4%E3%83%A1%E3%83%BC%E3%82%B8">条件付期待値のイメージ</h2>
<p>イメージはまさに$L^2$の直交射影としてのイメージが優秀になるが$L^1$では成り立たないので他のアプローチを考える。ここで <strong>シグマ加法族の細かさを情報多さ</strong> だと考える。そして確率変数$X$は$σ(X)$の情報の多さを持つものだと考える。そして画像のように、$E[X|G]$とは$X$を$G$の篩にかけて残ったものと考える。</p>
<p><img src="https://yukimaru77.github.io/practice/測度論的確率論/条件付期待値.jpg" alt="画像がなかった時の代替テキスト"></p>
<h2 id="%E6%9D%A1%E4%BB%B6%E4%BB%98%E6%9C%9F%E5%BE%85%E5%80%A4%E3%81%AE%E6%80%A7%E8%B3%AA">条件付期待値の性質</h2>
<ul>
<li>正定値性。$X\geqq0$ならば$E[X|G]\geqq0$</li>
<li>単調収束定理。$(X_n)<em>{n\geqq1}$が増大列で$X$に収束するなら$(E[X_n|G])</em>{n\geqq1}$は$E(X|G)$に収束する。</li>
<li>線形性。$E[aX+bY|G]=aE[X]+bE[Y]$</li>
<li>$E[E[X|G]]=E[X]$(ふるいに掛けてから期待値を取るのと最初から期待値を取るのは同じ)</li>
<li>$G\subset H$の時、$E[E[X|H]|G]=E[X|G]$(いっぱい通してから少なく通すのと最初から少なく通すのは同じ)</li>
<li>$X$が$G-$可測なら$E[X|G]=X$(篩にかけても同じ)</li>
<li>$σ(X)$と$G$が独立ならば$E[X|G]=E[X]$(情報が無いときのXの最良の推定値は期待値)</li>
</ul>

</article>
</body>
<script>
	elements = document.getElementsByTagName("h2");
	table_of_contents = document.createElement("ul");
	h2=document.createElement("h2");
	h2.textContent="目次"
	table_of_contents.appendChild(h2)
	for (  var i = 0;  i < elements.length;  i++  ) {
		console.log(elements[ i ]);
		const newElement_li = document.createElement("li");
		const newElement_a = document.createElement("a");
		newElement_a.href="#"+elements[ i ].id;
		newElement_a.textContent = elements[ i ].textContent;
		newElement_li.appendChild(newElement_a);
		table_of_contents.appendChild(newElement_li);
		
	}
	parents=document.getElementsByClassName("markdown-body")[0];
	h1 = document.getElementsByTagName("h1")[0];
	parents.insertBefore(table_of_contents, h1.nextSibling)
</script>
</html>